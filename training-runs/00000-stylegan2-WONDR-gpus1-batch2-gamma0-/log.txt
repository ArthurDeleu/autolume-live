Loading training set...
/home/arthurdeleu/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:146: UserWarning: 
NVIDIA GeForce RTX 3070 Ti Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.
If you want to use the NVIDIA GeForce RTX 3070 Ti Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))

Num images:  1408
Image shape: [3, 512, 512]
Label shape: [0]

Constructing networks...
starting G epochs:  0.0
Process Process-2:
Traceback (most recent call last):
  File "/home/arthurdeleu/miniconda3/envs/autolume_official/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/arthurdeleu/miniconda3/envs/autolume_official/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/train.py", line 390, in main
    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/train.py", line 99, in launch_training
    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/train.py", line 47, in subprocess_fn
    training_loop.training_loop(rank=rank, **c)
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/training/training_loop.py", line 179, in training_loop
    img, _ = misc.print_module_summary(G, [z, c])
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/torch_utils/misc.py", line 216, in print_module_summary
    outputs = module(*inputs)
  File "/home/arthurdeleu/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1148, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/architectures/custom_stylegan2.py", line 587, in forward
    ws = self.mapping(z, c, truncation_psi=truncation_psi, truncation_cutoff=truncation_cutoff, update_emas=update_emas)
  File "/home/arthurdeleu/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1148, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/architectures/custom_stylegan2.py", line 234, in forward
    x = normalize_2nd_moment(z.to(torch.float32))
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/torch_utils/misc.py", line 103, in decorator
    return fn(*args, **kwargs)
  File "/media/arthurdeleu/T7/autolumelive_colab/autolumelive_colab/architectures/custom_stylegan2.py", line 24, in normalize_2nd_moment
    return x * (x.square().mean(dim=dim, keepdim=True) + eps).rsqrt()
RuntimeError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/arthurdeleu/miniconda3/envs/autolume_official/lib/python3.10/multiprocessing/process.py", line 317, in _bootstrap
    util._exit_function()
  File "/home/arthurdeleu/miniconda3/envs/autolume_official/lib/python3.10/multiprocessing/util.py", line 357, in _exit_function
    p.join()
  File "/home/arthurdeleu/miniconda3/envs/autolume_official/lib/python3.10/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/arthurdeleu/miniconda3/envs/autolume_official/lib/python3.10/multiprocessing/popen_fork.py", line 43, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/arthurdeleu/miniconda3/envs/autolume_official/lib/python3.10/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/arthurdeleu/.local/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 136172) is killed by signal: Terminated. 
